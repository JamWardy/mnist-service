import io
from pathlib import Path
from typing import Tuple

import torch
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from PIL import Image
from torchvision import transforms

from model.model import MnistNet

# FastAPI to handle the back-end
app = FastAPI(title="MNIST Classification Service")

# Create path to the trained PyTorch model
BASE_DIR = Path(__file__).resolve().parent
MODELS_DIR = BASE_DIR.parent / "models"
MODEL_PATH = MODELS_DIR / "mnist_net.pt"

# Load model onto GPU if it's available, otherwise the CPU
device = torch.device("cpu")

# Load the trained MNIST model once when the app is initialized
model = MnistNet()
model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
model.eval()

# Preprocess image using standard MNIST training transformation
transform = transforms.Compose(
    [
        transforms.Grayscale(num_output_channels=1),
        transforms.Resize((28, 28)),
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,)),  # Mean and SD over whole MNIST dataset
    ]
)

def predict_digit(image: Image.Image):
    # Apply preprocessing and add batch dimension to get (1, 1, 28, 28)
    img = transform(image).unsqueeze(0) 

    # Disable gradient computation for faster inference
    with torch.no_grad():
        # Run the model and get class probabilities
        output = model(img)
        probabilities = torch.softmax(output, dim=1)[0]  # Only one item in batch
        confidence, predicted = torch.max(probabilities, dim=0)

    return int(predicted.item()), float(confidence.item()), probabilities.tolist()

@app.post("/predict")
# Receive an uploaded file and run the prediction
async def predict(file: UploadFile = File(...)):
    if file.content_type not in {"image/png", "image/jpeg", "image/jpg"}:
        raise HTTPException(status_code=400, detail="Invalid image type")

    contents = await file.read()
    try:
        # Convert raw bytes into a greyscale image
        image = Image.open(io.BytesIO(contents)).convert("L")
        digit, confidence, probabilities = predict_digit(image)
    except Exception:
        raise HTTPException(status_code=400, detail="Could not read image")
    return JSONResponse(
        {
            "digit": digit,
            "confidence": confidence,
            "probabilities": probabilities,
        }
    )

FRONTEND_DIR = BASE_DIR / "frontend" / "dist"

# Only run when front-end has been built by Vite
if FRONTEND_DIR.exists():
    # Attach a static file handler to the app, so /assets routes to files in /frontend/dist/assets
    app.mount(
        "/assets",
        StaticFiles(directory=FRONTEND_DIR / "assets"),
        name="assets",
    )

    # On a GET request to /, serve /frontend/dist/index.html
    @app.get("/", include_in_schema=False) # Don't show / in autogenerated docs
    async def serve_frontend_root():
        return FileResponse(FRONTEND_DIR / "index.html")

# Mangum handler for Lambda
from mangum import Mangum
handler = Mangum(app)